current state

tile boxes
input: jpg/png 
-> BGR by cv2.imread + resize
-> binary edge map (preprocess) 
-> list of tuples indicating tile box outline (detect hand_tiles) 

classification
input: jpg/png -> 
BGR by cv2.imread + resize 
-> list of tile images (BGR) (result of extract tile images, using tile box outline tuple list) 
-> classification (using inference.py ie cnn model on list of tile images) (SUPPOSED TO CONVERT TO RGB ON THIS STEP BUT ITHINK NVR)